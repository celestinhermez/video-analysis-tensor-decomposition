{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using numpy backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import tucker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read all of our files, and get the number of frames in each one. When reading them as tensors we will truncate to the one with the smallest number of frames. I strived to take videos of the same length (~11s), but small discrepancies are bound to exist. For our particular application, truncation ought not to matter too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(321, 328)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create VideoCapture objects\n",
    "parking_lot = cv2.VideoCapture('parking_lot.MOV')\n",
    "patio = cv2.VideoCapture('patio.MOV')\n",
    "\n",
    "# Get number of frames in each video\n",
    "parking_lot_frames = int(parking_lot.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "patio_frames = int(patio.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "parking_lot_frames, patio_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080 1920\n",
      "1080 1920\n"
     ]
    }
   ],
   "source": [
    "# Get dimensions of each frame\n",
    "parking_lot_height = int(parking_lot.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "parking_lot_width = int(parking_lot.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "patio_height = int(patio.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "patio_width = int(patio.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "print(parking_lot_height, parking_lot_width)\n",
    "print(patio_height, patio_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the number of frames and the dimensions of the frames, we will need a 4D tensor (321x1080x1920x3) to hold these videos:\n",
    "- 321 for the frames of the images (we truncate the extra frames for the patio video)\n",
    "- 1080x1920 for the height and width of the images\n",
    "- 3 for the RGB color channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create desired arrays\n",
    "parking_lot_array = []\n",
    "patio_array = []\n",
    "\n",
    "# Keep track of the frame\n",
    "patio_frame_nb = 0\n",
    "\n",
    "# Convert the parking lot video\n",
    "while parking_lot.isOpened():\n",
    "    ret, frame = parking_lot.read()\n",
    "    if not ret:\n",
    "        break    \n",
    "    parking_lot_array.append(frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "# Convert the patio video\n",
    "while patio.isOpened() and patio_frame_nb < 321:\n",
    "    ret, frame = patio.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    patio_array.append(frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    patio_frame_nb += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Release the capture now that we don't need it anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_lot.release()\n",
    "patio.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create tensors out of the NumPy arrays for use with the TensorLy library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensors from matrices\n",
    "parking_lot_tensor = tl.tensor(parking_lot_array)\n",
    "patio_tensor = tl.tensor(patio_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up later steps, we randomly select frames of the tensors to focus on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "random.seed(42)\n",
    "random_frames = random.sample(range(1, 321), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these random frames to subset the tensors\n",
    "subset_parking_lot = parking_lot_tensor[random_frames,:,:,:]\n",
    "subset_patio = patio_tensor[random_frames,:,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A natural way of comparing two tensors is to compute the norm of the difference between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180197.9867312618"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parking_patio_naive_diff = tl.norm(subset_parking_lot - subset_patio)\n",
    "parking_patio_naive_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the tensors, we can perform Tucker decomposition to get a more robust representation of the tensor (using the resulting core tensor) to get rid of noise and get a better sense of the similarity between two videos.\n",
    "\n",
    "The main tuning parameter is the n-rank of the tensor. We use a simple version of AIC to compute the optimal n-rank for each tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tucker(parking_lot_tensor, ranks = [1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
